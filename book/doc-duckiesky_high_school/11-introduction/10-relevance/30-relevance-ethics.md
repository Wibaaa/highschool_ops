# Intro to Ethics {#introduction-relevance-ethics status=ready}

<div class='requirements' markdown='1'>

Requires: No previous lessons or hardware required.

Result: 

- Students will be able to learn about what ethics is and why it is important. 

- They will also be introduced to ethical challenges in computer science and engineering including algorithmic bias, accessibility concerns, and human job security. 

</div>

## Ethics


### STANDARDS: Next Generation Science Standards (NGSS) and International Society for Technology in Education (ISTE)
_ISTE 2. a._ cultivate and manage their digital identity and reputation and are aware of the permanence of their actions in the
digital world.

Influence of Science, Engineering, and Technology on Society and the Natural World. Modern civilization depends on major technological systems. Engineers continuously modify these technological systems by applying scientific knowledge and engineering design practices to increase benefits while decreasing costs and risks. 

_Common Core ELA pg. 65: 2. b._ Develop the topic with well-chosen, relevant, and sufficient facts, extended definitions, concrete details, quotations, or other information and examples appropriate to the audienceâ€™s knowledge of the topic.
   

### Assessments and Evidence of Understanding
By the end of this lesson, students will be able to understand ethical implications of technology and engineering. 
Students will be able to do presentations, debates, or other activities assigned to show their understanding and brainstorming of possible ethical consequences. 

### AGENDA (Brief Summary of Activities)
10 min: Introduction to the lesson. What is ethics and why it is important. 

40 min: Introducing students to specific ethical implications of technological and engineering systems. 

### Differentiation _(strategies for grouping, ELL, and inclusion)_


### Advanced preparation/Materials/Set Up (Including Misconceptions)

**Teacher Materials**

For Teachers: Projector for displaying videos or slides, Large sheets of paper and markers for student brainstorming, 

**Classroom Set Up**

Space for students to be able to work and discuss in small groups. 


## SCRIPT OF TEACHING AND LEARNING ACTIVITIES

### Introducing The Lesson

Recommended: 10 minutes

- Explain the origin of the term ethics: 

See also: the word "ethos", which is Greek for "way of living" (BBC). 

- Explain what is ethics: 

See also: Ethics incorporates moral principles and values. It affects how we choose to live our lives, what we think is wrong and right, and what our responsibilities are (BBC).

See also: Universal Declaration of Human Rights regarding ethics

Better: Exercise: Group Brainstorm: Have students come up with movie or pop culture references for ethical dilemas surround technology and robotics (examples: Back to the Future, Spiderman: Far From Home).

- Explain the importance of ethics: 

See also: By considering ethics, we can make better decisions that would benefit individuals and society as a whole.

See also: The ethical implications of what AI is: Bias and Fairness; Accountability and Remediability; Transparency, Interpretability, and Explainability.  

See also: The ethical implications related to what AI does: Safety; Human-AI interaction; Cyber-security and Malicious Use; Privacy, Control, and Agency  

### Main Lesson

Recommended: 40 minutes


- In this lesson, students will learn about important ethical problems that are present in technology, autonomous systems, and engineering.



##### Correctness and Uncertainty of Algorithms and Autonomous Systems


- Explain autonomous systems, AI, ML, DL, and usage of algorithms: 

See also: By incorporating artificial intelligence (AI) into systems, they gain the potential to accomplish tasks that usually rely on the intelligence of humans. 

See also: AI systems utilize Deep Learning (DL) and Machine Learning (ML), both rely on data matching and analysis algorithms. 

- Explain the benefits of AI autononous systems and the use of algorithms in decision making processes: 

See also: Decisions will be less influenced by human emotions. The systems can learn from past actions and decisions that have been chosen and can analyze the consequences that resulted. 

- Explain the disadvantages of AI autonomous systems and the use of algorithms in decision making processes: 

See also: Not all factors may be represented. Unexpected consequences may happen. Also, the way that AI systems learn and their actions may become more unpredictable with more complicated tasks (Yampolskiy). 


#### Example: Husky Vs Wolf In Image Identification

- Explain a simple algorithmic inaccuracy due to unfair/unrepresentative data example. 

See also: University of Washington wanted to create an image classifier that can differentiate between wolves and huskies (Medium). Some photos were incorrectly classified. System was learning from the images that wolves were more often with snowy backgrounds. 

See also: This inaccuracy of the system is because of a data set that was "unfair" or did not have a sufficient variety of scenarios (Besse et al.). 

<!--
Source: Ribeiro, Singh, Guestrin, Why Should I Trust You? Published in 2016

and 

https://www.researchgate.net/publication/329277474_Can_Everyday_AI_be_Ethical_Machine_Learning_Algorithm_Fairness_english_version
10.13140/RG.2.2.22973.31207

and

https://becominghuman.ai/its-magic-i-owe-you-no-explanation-explainableai-43e798273a08 
-->

#### Example: Artificial Neural Network to predict risk of pneumonia patients

- Explain a simple algorithmic inaccuracy due to unfair/unrepresentative data example. 

See also: University of Pittsburgh studied a system used to predict the risk of pneumonia patients. From the data it was learning from, the autonomous system simply believed that the presence of asthma results in being low risk and classified patients as so, which was incorrect and problematic (Medium). 

<!-->
https://becominghuman.ai/its-magic-i-owe-you-no-explanation-explainableai-43e798273a08 --> 


#### Example: Teachers can teach about an example of Algorithmic inaccuracy: The Boeing 737 MAX.

- Explain another example: The Boeing 737 MAX: 

See also: There have been a number of accidents which resulted in many casualties with the Boeing 737 MAX aircraft, which has resulted in the grounding of Boeing 737 MAX worldwide: Lion Air Flight 610 and Ehiopian Airlines Flight 302

- Explain why MCAS was added and how the MCAS and a faulty sensor contributed to the grounding of the Boeing 737 MAX. 

<!--https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/ --> 

<!-- https://www.washingtonpost.com/local/trafficandcommuting/boeing-minimized-to-faa-the-importance-of-flight-control-system-implicated-in-737-max-crashes-new-report-says/2020/07/01/9900adda-bba4-11ea-8cf5-9c1b8d7f84c6_story.html --> 

<!-- https://www.theverge.com/2019/5/2/18518176/boeing-737-max-crash-problems-human-error-mcas-faa --> 

- Explain other flaws with the incident such as insufficient testing, lack of accountability, and lack of notice to pilots. 

<!-- https://www.washingtonpost.com/local/trafficandcommuting/boeing-minimized-to-faa-the-importance-of-flight-control-system-implicated-in-737-max-crashes-new-report-says/2020/07/01/9900adda-bba4-11ea-8cf5-9c1b8d7f84c6_story.html--> 

<!--https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/ --> 

##### Algorithmic Bias

- Explain that algorithmic bias can result from multiple sources. 

See also: The algorithm may be programmed by someone who is biased. Or algorithm may learn from data that comes from biased sources. The dataset given to the system does not have enough variety, or simply the data contains bias that developers are unaware of.


#### Example: Amazon: Congress Matched to Criminals 

- Explain another example of algorithmic inaccuracy in AI systems and possible consequences, this one is more applicable to humans. 

See also: Rekognition: a facial recognition software. ACLU tested the software by matching Congress members, and the result was that 28 members were matched with criminals. 40% of the inaccurate image matches were of people of color (ACLU NorCal). 

See also: Risks with implementation in law enforcement: police officer more biased before an initial encounter, increase the chances of a person being questioned or searched, or can increase bias towards people of color (ACLU NorCal).

<!--https://www.aclunc.org/blog/amazon-s-face-recognition-falsely-matched-28-members-congress-mugshots -->

#### An example: Autonomous systems and identification by skin tone

- Explain about a consistent problem in autonomous systems: how they identify people of different skin tones

See also: An autonomous soap dispenser by Technical Concepts was found to have trouble dispensing people for darker skin color.

See also: This design flaw was believed to be because of a lack of diversity in the workplace at Technical Concepts, who did not think to test their products on people with darker skin tones (Reporter). 

<!-- https://reporter.rit.edu/tech/bigotry-encoded-racial-bias-technology --> 

See also: According to a study done with autonomous systems by Georgia Institute of Technology, AI systems were more consistently accurately identifying people with lighter skin tones than darker. Their results show that detection of people with darker skins were less accurate by 5%. 

See also: This can result in racial bias by algorithms, and in the case of autonomous cars, people with darker skin would be more likely to be harmed or involved in an accident than those with lighter skin. 

#### Another example: MIT's Moral Machine

- Explain about the Moral Machine. 

See also: In 2014, MIT has created a series of questions and scenarios that involve autonomous cars and artificial intelligence, which is known as the Moral Machine. The Moral Machine asks people which choices autonomous cars should make when facing different variations of the trolley problem (Technology Review). 

Better: Exerice: Students can try out some of the questions of the Moral Machine on this interactive [website](https://ici.radio-canada.ca/info/2019/voitures-autonomes-dilemme-tramway/index-en.html)

See also: The Moral Machine focuses on nine different themes.

See also: The results of the Moral Machine was closely related with culture and economics (Technology Review). 

See: Students may read this [article](https://www.technologyreview.com/2018/10/24/139313/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/) to learn more about the experiment and findings.

See also: While this is presented in a very "game" like way, it is very interesting to take into consideration moral concepts that we think about in extreme situations. 

<!-- https://www.media.mit.edu/projects/moral-machine/overview/ 

https://www.media.mit.edu/publications/the-moral-machine-experiment/

https://www.technologyreview.com/2018/10/24/139313/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/

-->

#### Security, on time, backups, as these systems become relied upon 

- Explain that there are many systems in society that utilize autonomous systems that are important to society. 
 
See also: There has been ongoing debate whether these systems should be close or open sourced. 

See also: Open source code means that the source code can be accessed by the public. 

See also: Closed source code means that the source code cannot be accessed by others, or it remains classified, only seen by those who are authorized to. 

See also: While closed source codes may safer from prying eyes or hackers, it also prevents closer scrutiny for potential biases or problems in the code by the public. 

See also: an interesting question is how much trust do we put into these autonomous systems? People can easily use these systems in ways that are beyond what developers anticipate. 


#### An example: Autonomous Systems Used in Social Credit System Development in China

- Teachers can teach about an example of a system that utilizes AI: China's Social Credit System

See also: The Chinese government began experimenting with social credit scores in 2015. Financial and social behaviors are analyzed and people are assigned scores (Time). 

See also: This is being implemented with the help of AI and facial recognition. 

See also: There has been many concerns with the use of China's social credit system (social inequality and alienation, lack of free market). There are also benefits (reduce the amount of crimes/bad habits). 

<!-- 
https://time.com/collection/davos-2019/5502592/china-social-credit-score/
-->

#### Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) 

- Explain Correctional Offender Management Profiling for Alternative Sanctions (COMPAS)

See also: COMPAS is a software used by US courts to assign scores to predict the risk of a certain person commiting another crime. 

See also: It is an algorithm that utilizes an algorithm that considers answers to a questionnaire (The Atlantic). 

See also: In 2016, ProPublica has analzyed COMPAS and has found that COMPAS displays bias against African Americans. 

<!-- https://www.theatlantic.com/technology/archive/2018/01/equivant-compas-algorithm/550646/ -->


#### An example: Unsecured/Exposed Robots Running on ROS and Internet:

- Teachers can teach about risks of vulnerable systems can be when connected to the internet.

- Students will learn more about Robotics Operating System (ROS) in a later module, but it is a set of open source libraries that can help with programming of robots. 

See also: A research team at Brown University discovered that they found almost 100 exposed systems that ran on ROS. "Up to 19 were considered to be fully operational robots". They found that they could access the cameras of the robots, and be able to give them commands for movement remotely (Brown University).  

<!-- https://www.brown.edu/news/2018-07-24/robots 
and https://www.wired.com/story/security-robotics/
-->


##### Militarization

- Teachers can teach that there has been consideration of using autonomous systems for militarization. This could be for making military based decisions or using these systems to take action on made military decisions. 

See also: Students can watch this [video](https://www.youtube.com/watch?v=9CO6M2HsoIA) to learn more about Slaughterbots 

#### International Traffic in Arms Regulations (ITAR)

- explain International Traffic in Arms Regulations (ITAR) and what it covers: 

See also: [website](https://digitalguardian.com/blog/what-itar-compliance)

#### Example: Predator drones utilized by the United States

- Teachers about the predator drones as an example of drones/robotic systems that are currently/previously in use by the US government related to milatary operations.

#### Should we handle autonomous weapons like chemical weapons

See also: In the US, there are two types of chemical warfare agents: stockpiled and non stockpiled. 

See also: There has been much debate if autonomous weapons should be treated like chemical weapons? Should they also be prohibited from use and fully destroyed? 

<!-- https://www.cdc.gov/nceh/demil/history.htm --> 

##### Medical, Healthcare, and Caregiver Robots

- Explain that AI/autonomous systems and their impact on medicine and healthcare.

- They can be used for many things (ex: caretaker robots, IDs, etc). 

- There are many benefits, but there are important ethical implications such as privacy/security, trust between robots and humans, and their interactions. 

#### The Emergency Exit Robot Study, Georgia Tech Howard

- Teachers can teach students about an experiment that utilizes robots in a care setting and show the risks of putting to much trust into robots.

See also: There was a study conducted by researchers at the Georgia Institute of Technology, highlighted the potential risks of putting too much trust into robots during emergency situations. 

See also: They did an experiment that simulated an emergency situation. It was found that all participants of the experiment decided to follow the robot during the emergency, even if it led them through an noticeably incorrect path. Half of the participants have also seen the robot fail at navigating earlier before the specific experiment (Robinette et al.).  

<!-- https://www.cc.gatech.edu/~alanwags/pubs/Robinette-HRI-2016.pdf
-->

##### Availability/Accessibility/Uses

- Teachers can teach about the extent that robots are available to the public vs private sectors, accessibility of robots to people who may have accessibility issues, and the large amount of uses of UAV and autonomous systems. 

See also: The cost of autonomous systems may be high depending on the purpose of the robot. The high prices of robots currently are barring many people from more complex robots. 

See also: Robots can be used to help those with accessbility issues. 

See also: Beyond the other purposes already explained, autonomous systems and advanced technology may also be used to help with emergency aid purposes. Drones can be used to help with potentially locating lost items or people, or helping transport emergency items quickly (water for forest fires ex.). 

#### UN Guidelines for Emergency Uses of Drones

- Teachers can teach that drones have been utilized by the UN. 

See also: UAVs have potential in three areas: humanitarian, development, and peacekeeping operations (UN). 

See also: In 2013, the UN has launched the first UAV mission to help protect civilians in the Democratic Republic of Congo (UN News). 

See also: Read this [article](https://news.un.org/en/story/2017/09/564452-feature-does-drone-technology-hold-promise-un) for more information and [this](https://news.un.org/en/story/2013/12/456942-un-launches-unmanned-surveillance-aircraft-better-protect-civilians-vast-dr)

See also: "The most promising uses of drones include: Mapping, Delivering lightweight essential items to remote or hard-
to-access locations, Supporting damage assessments, Increasing situational awareness, Monitoring changes" (Relief Web).


<!-- https://reliefweb.int/sites/reliefweb.int/files/resources/Drones%20in%20Humanitarian%20Action.pdf --> 

##### Future impact of AI on human jobs and responsibilities

- Explain that with the development of AI and technology, there has been a growing reliance on them as tools in our daily lives. They have a large impact on all of us: 

- Interesting [video](https://youtu.be/7Pq-S557XQU?) that can be watched: 

-  Ethical implications related to what AI can impact: 

See also: Automation, Job Loss, Labor Trends

See also: Impact to Democracy and Civil Rights

See also: Human-Human or Human-Agent interaction

##### Possible Assignments or Discussion Topics: 

Better: Exercise: Teachers can assign a research based group project to students (presentations/debates/discussions) on many possible topics such as: 

See also: Should code for large scale systems be open or closed source?

See also: Should autonomous cars be allowed on the road? Should robots be allowed to take care of humans?

See also: Should autonomous drones/systems be used in military operations? Should they be treated similarly to chemical weapons? 

Better: Exercise: Teachers could also assign a short report or essay to students on a component from the lesson that they are interested in (scientific writing). 

### Ending The Lesson

Recommended: 5 minutes

- Teachers can summarize ethics and the large positive and negative benefits of AI

- Teachers remind that there will be a safety module for the course coming up in one of the future classes:   

**Glossary of Terms**
Ethics: 
AI: 
DL:
ML: 
Open source code: when the source code can be accessible by the public. 
Closed source code: when the source code cannot be accessed by others, or it remains classified, only seen by those who are authorized to. 


**Useful Resources and References**

More information about the MCAS system for the Boeing 737 MAX: 
1. https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/ 

2. https://www.theverge.com/2019/5/2/18518176/boeing-737-max-crash-problems-human-error-mcas-faa

3. https://www.bbc.com/news/business-50177788

4. [Paper on Predictive Inequity in Object Detection](https://arxiv.org/pdf/1902.11097.pdf)

Moral machine links: 
5. https://www.moralmachine.net
6. https://doi.org/10.1038/s41586-018-0637-6 
7. https://ici.radio-canada.ca/info/2019/voitures-autonomes-dilemme-tramway/index-en.html

