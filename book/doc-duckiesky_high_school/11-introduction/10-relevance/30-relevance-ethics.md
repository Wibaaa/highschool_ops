# Intro to Ethics {#introduction-relevance-ethics status=ready}

<div class='requirements' markdown='1'>

Requires: No previous lessons or hardware required.

Result: 

- Students will be able to learn about what ethics is and why it is important. 

- Students will be introduced to ethical challenges in computer science and engineering including algorithmic bias, accessibility concerns, and human job security. 

</div>

## Ethics


### STANDARDS: Next Generation Science Standards (NGSS) and International Society for Technology in Education (ISTE)
_ISTE 2. a._ cultivate and manage their digital identity and reputation and are aware of the permanence of their actions in the
digital world.

Influence of Science, Engineering, and Technology on Society and the Natural World. Modern civilization depends on major technological systems. Engineers continuously modify these technological systems by applying scientific knowledge and engineering design practices to increase benefits while decreasing costs and risks. 

_Common Core ELA pg. 65: 2. b._ Develop the topic with well-chosen, relevant, and sufficient facts, extended definitions, concrete details, quotations, or other information and examples appropriate to the audienceâ€™s knowledge of the topic.
   

### Assessments and Evidence of Understanding
By the end of this lesson, students will be able to understand ethical implications of technology and engineering. 
Students will be able to do presentations, debates, or other activities assigned to show their understanding and brainstorming of possible ethical consequences. 

### AGENDA (Brief Summary of Activities)
10 min: Introduction to the lesson. What is ethics and why it is important. 

40 min: Introducing students to specific ethical implications of technological and engineering systems. 

### Differentiation _(strategies for grouping, ELL, and inclusion)_


### Advanced preparation/Materials/Set Up (Including Misconceptions)

**Teacher Materials**

- Projector for displaying videos or slides
- Large sheets of paper and markers for student brainstorming in small groups
- Print out [note sheets](https://docs.google.com/document/d/17OSygnSXLueR2K5h-1ncwIuaMdFhb5mv0fAuhiSRw9w/edit?usp=sharing) for students to help take notes
- reference the student textbook for more detailed explanations of concepts and examples

**Classroom Set Up**

- Space for students to be able to work and discuss in small groups. 
- Make sure each group of students have at least one large sheet of paper and a number of markers.

## SCRIPT OF TEACHING AND LEARNING ACTIVITIES

### Introducing The Lesson

Recommended: 10 minutes

Hook: There are many important decisions that need to be made for situations regularly. With drones or any AI or autonomous system that you are creating or using, students must understand that there are certain moral implications/ethics/principles that must be considered and have different consequences on others. 

Better: Exercise: Group Brainstorm: Ask students brainstorm on paper in groups about ethics and important/common topics addressed by ethics. Have students come up with movie or pop culture references for ethical dilemmas surround technology and robotics.


- Examples of pop culture/movie references: 
     - Spider-Man: Far From Home: Mysterio used autonomous and programmed drones to create the illusions, cause harm and chaos in society. Also Peter's ordered drone strike on his classmate on the bus, example of almost civilian casualty/warfare. 
     - Avengers movies: Tony Stark's AI Jarvis, many instances of facial recognition in Tony's labs and suits, and the enemy Ultron (the whole let robots take over the world)
     - Black Mirror TV show: many episodes revolving around technology and society. This [article](https://www.forbes.com/sites/cognitiveworld/2019/02/24/pop-culture-ai-and-ethics/#1491b1c17cd2) has particular examples of episodes and AI impacts on society

- Explain the origin of the word ethics and what is ethics:
     -  The Universal Declaration of Human Rights includes a [list](https://www.un.org/en/udhrbook/pdf/udhr_booklet_en_web.pdf) of fundamental human rights which often closely relates to ethics 

- Explain the importance of ethics and explain ethical implications:
     - [what AI is](https://towardsdatascience.com/the-hitchhikers-guide-to-ai-ethics-part-2-what-ai-is-c047df704a00) : Bias and Fairness; Accountability and Remediability; Transparency, Interpretability, and Explainability   
     - [what AI does](https://towardsdatascience.com/the-hitchhikers-guide-to-ai-ethics-part-3-what-ai-does-its-impact-c27b9106427a): Safety; Human-AI Interaction; Cybersecurity and Malicious Use; Privacy, Control, and Surveillance

### Main Lesson

Recommended: 40 minutes

- In this lesson, students will learn about important ethical problems that are present in technology, autonomous systems, and engineering.

##### Correctness and Uncertainty of Algorithms and Autonomous Systems

Better: Exercise: Students brainstorm different autonomous systems they have heard about or used. Students should think about whether they trust these specific systems and why or why not?

- Explain autonomous systems, AI, ML, DL, and usage of algorithms 
- Explain the benefits and disadvantages of autonomous systems and the use of algorithms in decision making processes

#### Example: Husky Vs Wolf in Image Identification

- Explain an example of algorithmic inaccuracy due to unfair/unrepresentative data example with differentiating huskies and wolves

See also: [Paper](https://www.researchgate.net/publication/329277474_Can_Everyday_AI_be_Ethical_Machine_Learning_Algorithm_Fairness_english_version
10.13140/RG.2.2.22973.31207) about fairness involved in algorithms that undergo ML

#### Example: Artificial Neural Network Predicting Risk of Pneumonia Patients

- Explain a simple algorithmic inaccuracy due to unfair/unrepresentative data example with identifying risk of pneumonia patients

See also: [Article](https://becominghuman.ai/its-magic-i-owe-you-no-explanation-explainableai-43e798273a08) with more detail about Pneumonia and Asthma Risk System


#### Example: The Boeing 737 MAX

- Explain the incidents involving the Boeing 737 MAX
- Explain why MCAS was added and how the MCAS and a faulty sensor contributed to the grounding of the Boeing 737 MAX 
- Explain other flaws with the incident

##### Algorithmic Bias

Better: Exercise: Students should brainstorm about potential sources of algorithmic bias

Better: Exercise: Students can play this [game](https://www.survivalofthebestfit.com) to learn more about machine learning bias in the workforce

- Explain that algorithmic bias can result from multiple sources

#### Example: Congress Matched to Criminals by Rekognition

- Explain another example of algorithmic inaccuracy, this one is regarding facial recognition which is more applicable to humans
- Explain risks with its implementation in law enforcement

#### An example: Autonomous Systems Identification by Skin Tone

- Explain about a consistent problem in AI systems: how they identify people of different skin tones
     - autonomous soap dispenser and autonomous cars have trouble with this
- AI systems were less accurate at detecting people of darker skins by 5% (Georgia Institute of Tech)
- identify possible reasons that contributed to these systems not working such as lack of diversity in workplace, IR sensors

See also: [article](https://reporter.rit.edu/tech/bigotry-encoded-racial-bias-technology) about encoded racial bias in technology

#### Another example: MIT's Moral Machine

Better: Exercise: Students can try out some of the questions of the Moral Machine on this interactive [website](https://ici.radio-canada.ca/info/2019/voitures-autonomes-dilemme-tramway/index-en.html)

- Explain that the Moral Machine focuses on nine different themes
- Note about the correlation between results of the Moral Machine and culture and economics 

See also: Students may read this [article](https://www.technologyreview.com/2018/10/24/139313/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/) to learn more about the experiment and findings.

Note: While this is presented in a very game-like way, it is very interesting to take into consideration moral concepts that we think about in extreme situations. 

#### Security/Systems Utilized in Society

Better: Exercise: Students can brainstorm other ways that AI/autonomous systems/algorithms are used in systems used in society. 

- Explain that there are many systems in society that utilize autonomous systems that are important to society

- Explain open source and close sourced code

Better: Exercise: Students think or write down about whether important systems/algorithms should be close or open sourced? 

Better: Exercise: Based on what they have learned so far, has their original opinion changed about how much trust do we put into these autonomous systems? 

#### An example: Use of Biometric Data in Society 

Better: Exercise: Students brainstorm about systems, apps, tools that use biometric data (ex: FaceID, tracking down crime suspects, access to restricted buildings,  access to important services such as healthcare)
     
- Explain advantages and disadvantages of biometric data in society: 
     - compare with pros and cons of other methods of verification (passwords, emails, hardware key)

- Importance of using multiple of these verification methods

See also: [Article](https://www.cnet.com/news/police-use-of-facial-recognition-gets-reined-in-by-uk-court/) about Police Use of Facial Recognition

#### An example: Autonomous Systems Used in Social Credit System Development in China

- Explain example of a system that utilizes AI: China's Social Credit System

Better: Exercise: Class or group discussion about potential advantages and disadvantages of this system. 

See also: [article](https://time.com/collection/davos-2019/5502592/china-social-credit-score/) on China's Social Credit System

#### An example: Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) 

- Explain Correctional Offender Management Profiling for Alternative Sanctions (COMPAS)

- Explain that COMPAS has displayed bias against African Americans. 

See also: [Article](https://www.theatlantic.com/technology/archive/2018/01/equivant-compas-algorithm/550646/)


#### An example: Unsecured/Exposed Robots Running on ROS and Internet:

- Teachers can teach about risks of vulnerable systems can be when connected to the internet

See also: [Article 1](https://www.brown.edu/news/2018-07-24/robots) and [Article 2](https://www.wired.com/story/security-robotics/)

Note: Students will learn more about Robotics Operating System (ROS) in a later module, but it is a set of open source libraries that can help with programming of robots. 

##### Militarization

- Explain the use of autonomous systems for militarization (to make military decisions, or to take direct action)

<!-- See also: Students can watch this [video](https://www.youtube.com/watch?v=9CO6M2HsoIA) to learn more about Slaughterbots -->

#### International Traffic in Arms Regulations (ITAR)

- Explain International Traffic in Arms Regulations (ITAR) and what it covers

See also: [website](https://digitalguardian.com/blog/what-itar-compliance)

#### Example: Predator drones utilized by the United States

- Explain predator drones as an example of drone systems that are in use by the US government for military operations

- Unmanned aerial vehicles face many ethical issues such as civillian casualties

Better: Exercise: Students can write a paper/debate in groups about whether they think predator drones should be used. 

#### Autonomous Weapons and Chemical Weapons

- Explain the different types of chemical warfare agents in US

See also: [History of US Chemical Weapons Elimination](https://www.cdc.gov/nceh/demil/history.htm)

See also: Class discussion: autonomous weapons should be treated like chemical weapons? Should they also be prohibited from use and fully destroyed? 

##### Medical, Healthcare, and Caregiver Robots

Better: Exercise: students can brainstorm where AI systems are utilized in healthcare

- Explain that there are many benefits, but there are important ethical implications:
     - privacy/security, trust between robots and humans, and their interactions 

#### Example: The Emergency Exit Robot Study, Georgia Tech Howard

Better: Exercise: Show of hands by students: would you follow a robot during an emergency? 

Better: Exercise: Show of hands: What if it seems to be going in a not so great path?

- Explain about experiment conducted by Georgia Institute of Technology

See also: [Study](https://www.cc.gatech.edu/~alanwags/pubs/Robinette-HRI-2016.pdf)

##### Availability/Accessibility/Uses

- Explain robots are available to the public vs private sectors, accessibility of robots to people who may have accessibility issues, and the large amount of uses of UAV and autonomous systems. 

- Explain the effect of robot costs on consumers 

- Explain that robots can help with humanitarian and emergency efforts

#### UN Guidelines for Emergency Uses of Drones

- Explain different uses of drones and UAVs by the UN. 

See also: Read this [article](https://news.un.org/en/story/2017/09/564452-feature-does-drone-technology-hold-promise-un) for more information on UN and drones

See also: Read this [article](https://news.un.org/en/story/2013/12/456942-un-launches-unmanned-surveillance-aircraft-better-protect-civilians-vast-dr) about UN's operation with unmanned aircraft in DR Congo

See also: Read this [article](https://reliefweb.int/sites/reliefweb.int/files/resources/Drones%20in%20Humanitarian%20Action.pdf) to learn more about Drones and Humanitarian Action

##### Future impact of AI on human jobs and responsibilities

- Explain that with the development of AI and technology, there has been a growing reliance on them as tools in our daily lives

- Interesting [video](https://youtu.be/7Pq-S557XQU?) that can be watched: 

-  Explain ethical implications related to what AI can impact: 
     - Automation, Job Loss, Labor Trends; Impact to Democracy and Civil Rights; Human-Human or Human-Agent interaction


### Ending The Lesson

Recommended: 5 minutes

- Summarize ethics and the large positive and negative benefits of AI

- Remind students that there will be a safety module for the course coming up in one of the future classes   

Better: Exercise: Teachers could also assign a short report/presentation/essay to students on a specific section of this lesson or overall how their opinions have changed before & after the lesson

**Useful Resources and References**

1. [Seattle Times Article](https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/) for more information about the MCAS system for the Boeing 737 MAX: 

2. [Verge Article](https://www.theverge.com/2019/5/2/18518176/boeing-737-max-crash-problems-human-error-mcas-faa) about other flaws involved in the Boeing incidents

3. [Washington Post Article](https://www.washingtonpost.com/local/trafficandcommuting/boeing-minimized-to-faa-the-importance-of-flight-control-system-implicated-in-737-max-crashes-new-report-says/2020/07/01/9900adda-bba4-11ea-8cf5-9c1b8d7f84c6_story.html) on the lack of notice to FAA about Boeing MCAS system


4. [Paper on Predictive Inequity in Object Detection](https://arxiv.org/pdf/1902.11097.pdf)

5. [Moral Machine Test](https://www.moralmachine.net)

6. [Paper](https://doi.org/10.1038/s41586-018-0637-6) on the Moral Machine Experiment  

7. [Interactive moral machine](https://ici.radio-canada.ca/info/2019/voitures-autonomes-dilemme-tramway/index-en.html)

8. [Article analyzing results from different countries](https://www.technologyreview.com/2018/10/24/139313/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/)

9. [Paper](https://www.researchgate.net/publication/329277474_Can_Everyday_AI_be_Ethical_Machine_Learning_Algorithm_Fairness_english_version
10.13140/RG.2.2.22973.31207) about Fairness involved in Algorithms that undergo ML

10. [Article](https://becominghuman.ai/its-magic-i-owe-you-no-explanation-explainableai-43e798273a08) with more detail about Pneumonia and Asthma Risk System and Wolf Vs Husky Identifier

11. [Article](https://www.aclunc.org/blog/amazon-s-face-recognition-falsely-matched-28-members-congress-mugshots) about Rekognition and its failed Congress classifications