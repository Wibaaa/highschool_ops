# Intro to Ethics {#introduction-relevance-ethics status=ready}

<div class='requirements' markdown='1'>

Requires: No previous lessons or hardware required.

Result: 

- Students will be able to learn about what ethics is and why it is important. 

- They will also be introduced to ethical challenges in computer science and engineering including algorithmic bias, accessibility concerns, and human job security. 

</div>

## Ethics


### STANDARDS: Next Generation Science Standards (NGSS) and International Society for Technology in Education (ISTE)
_ISTE 2. a._ cultivate and manage their digital identity and reputation and are aware of the permanence of their actions in the
digital world.

Influence of Science, Engineering, and Technology on Society and the Natural World. Modern civilization depends on major technological systems. Engineers continuously modify these technological systems by applying scientific knowledge and engineering design practices to increase benefits while decreasing costs and risks. 

_Common Core ELA pg. 65: 2. b._ Develop the topic with well-chosen, relevant, and sufficient facts, extended definitions, concrete details, quotations, or other information and examples appropriate to the audienceâ€™s knowledge of the topic.
   

### Assessments and Evidence of Understanding
By the end of this lesson, students will be able to understand ethical implications of technology and engineering. 
Students will be able to do presentations, debates, or other activities assigned to show their understanding and brainstorming of possible ethical consequences. 

### AGENDA (Brief Summary of Activities)
10 min: Introduction to the lesson. What is ethics and why it is important. 

40 min: Introducing students to specific ethical implications of technological and engineering systems. 

### Differentiation _(strategies for grouping, ELL, and inclusion)_


### Advanced preparation/Materials/Set Up (Including Misconceptions)

**Teacher Materials**

For Teachers: Projector for displaying videos or slides, Large sheets of paper and markers for student brainstorming, 

**Classroom Set Up**

Space for students to be able to work and discuss in small groups. 


## SCRIPT OF TEACHING AND LEARNING ACTIVITIES

### Introducing The Lesson

Recommended: 10 minutes

- Explain the origin of the word ethics

- Explain what is ethics

See also: Universal Declaration of Human Rights regarding ethics

Better: Exercise: Group Brainstorm: Have students come up with movie or pop culture references for ethical dilemas surround technology and robotics (examples: Back to the Future, Spiderman: Far From Home).

- Explain the importance of ethics: 

- Explain the ethical implications of what AI is and what AI does

### Main Lesson

Recommended: 40 minutes

- In this lesson, students will learn about important ethical problems that are present in technology, autonomous systems, and engineering.


##### Correctness and Uncertainty of Algorithms and Autonomous Systems

- Explain autonomous systems, AI, ML, DL, and usage of algorithms

- Explain the benefits of AI autononous systems and the use of algorithms in decision making processes

- Explain the disadvantages of AI autonomous systems and the use of algorithms in decision making processes

#### Example: Husky Vs Wolf In Image Identification

- Explain an example of algorithmic inaccuracy due to unfair/unrepresentative data example:  

See also: University of Washington created an image classifier that can differentiate between wolves and huskies (Medium). Some photos were incorrectly classified.
<!--
Source: Ribeiro, Singh, Guestrin, Why Should I Trust You? Published in 2016

and 

https://www.researchgate.net/publication/329277474_Can_Everyday_AI_be_Ethical_Machine_Learning_Algorithm_Fairness_english_version
10.13140/RG.2.2.22973.31207

and

https://becominghuman.ai/its-magic-i-owe-you-no-explanation-explainableai-43e798273a08 
-->

#### Example: Artificial Neural Network to predict risk of pneumonia patients

- Explain a simple algorithmic inaccuracy due to unfair/unrepresentative data example:

See also: University of Pittsburgh studied a system used to predict the risk of pneumonia patients. From the data it was learning from, the autonomous system simply believed that the presence of asthma results in being low risk and classified patients as so, which was incorrect and problematic (Medium). 

<!-->
https://becominghuman.ai/its-magic-i-owe-you-no-explanation-explainableai-43e798273a08 --> 


#### Example: Teachers can teach about an example of Algorithmic inaccuracy: The Boeing 737 MAX.

- Explain the incidents involving the Boeing 737 MAX

- Explain why MCAS was added and how the MCAS and a faulty sensor contributed to the grounding of the Boeing 737 MAX. 

<!--https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/ --> 

<!-- https://www.washingtonpost.com/local/trafficandcommuting/boeing-minimized-to-faa-the-importance-of-flight-control-system-implicated-in-737-max-crashes-new-report-says/2020/07/01/9900adda-bba4-11ea-8cf5-9c1b8d7f84c6_story.html --> 

<!-- https://www.theverge.com/2019/5/2/18518176/boeing-737-max-crash-problems-human-error-mcas-faa --> 

- Explain other flaws with the incident such as insufficient testing, lack of accountability, and lack of notice to pilots. 

<!-- https://www.washingtonpost.com/local/trafficandcommuting/boeing-minimized-to-faa-the-importance-of-flight-control-system-implicated-in-737-max-crashes-new-report-says/2020/07/01/9900adda-bba4-11ea-8cf5-9c1b8d7f84c6_story.html--> 

<!--https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/ --> 

##### Algorithmic Bias

- Explain that algorithmic bias can result from multiple sources:

See also: The algorithm may be programmed by someone who is biased. 

See also: Algorithm may learn from data that comes from biased sources. 

See also: The dataset given to the system does not have enough variety, or the data contains bias that developers are unaware of.

#### Example: Amazon: Congress Matched to Criminals 

- Explain another example of algorithmic inaccuracy in AI systems and possible consequences, this one is more applicable to humans. 

See also: Rekognition: a facial recognition software. ACLU tested the software by matching Congress members, and the result was that 28 members were matched with criminals. 40% of the inaccurate image matches were of people of color (ACLU NorCal). 

- Explain risks with its implementation in law enforcement

<!--https://www.aclunc.org/blog/amazon-s-face-recognition-falsely-matched-28-members-congress-mugshots -->

#### An example: Autonomous systems and identification by skin tone

- Explain about a consistent problem in AI systems: how they identify people of different skin tones

See also: autonomous soap dispenser by Technical Concepts had trouble dispensing people for darker skin color.

See also: autonomous cars had trouble sensing pedestrians of darker skin color.

- identify possible reasons that contributed to these systems not working such as lack of diversity in workplace, IR sensors

<!-- https://reporter.rit.edu/tech/bigotry-encoded-racial-bias-technology --> 

#### Another example: MIT's Moral Machine

- Explain about the Moral Machine. 

Better: Exerice: Students can try out some of the questions of the Moral Machine on this interactive [website](https://ici.radio-canada.ca/info/2019/voitures-autonomes-dilemme-tramway/index-en.html)

- Explain that the Moral Machine focuses on nine different themes

- Note about the correlation between results of the Moral Machine and culture and economics 

See: Students may read this [article](https://www.technologyreview.com/2018/10/24/139313/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/) to learn more about the experiment and findings.

Note: While this is presented in a very game-like way, it is very interesting to take into consideration moral concepts that we think about in extreme situations. 

<!-- https://www.media.mit.edu/projects/moral-machine/overview/ 

https://www.media.mit.edu/publications/the-moral-machine-experiment/

https://www.technologyreview.com/2018/10/24/139313/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/

-->

#### Security, on time, backups, as these systems become relied upon 

- Explain that there are many systems in society that utilize autonomous systems that are important to society. 

- Explain open source and close sourced code
 
- Explain there has been ongoing debate whether important systems and algorithms should be close or open sourced. 

See also: an interesting question is how much trust do we put into these autonomous systems? People can easily use these systems in ways that are beyond what developers anticipate. 


#### An example: Autonomous Systems Used in Social Credit System Development in China

- Teachers can teach about an example of a system that utilizes AI: China's Social Credit System

- Explain disadvantages/concerns with the use of China's social credit system (ie social inequality and alienation, lack of free market) and explain benefits (ie: reduce the amount of crimes/bad habits). 

<!-- 
https://time.com/collection/davos-2019/5502592/china-social-credit-score/
-->

#### Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) 

- Explain Correctional Offender Management Profiling for Alternative Sanctions (COMPAS)

- Explain that COMPAS displays bias against African Americans. 

<!-- https://www.theatlantic.com/technology/archive/2018/01/equivant-compas-algorithm/550646/ -->


#### An example: Unsecured/Exposed Robots Running on ROS and Internet:

- Teachers can teach about risks of vulnerable systems can be when connected to the internet.

See also: A research team at Brown University discovered that they found almost 100 exposed systems that ran on ROS. "Up to 19 were considered to be fully operational robots". They found that they could access the cameras of the robots, and be able to give them commands for movement remotely (Brown University). [Article 1](https://www.brown.edu/news/2018-07-24/robots) and [Article 2](https://www.wired.com/story/security-robotics/)

Note: Students will learn more about Robotics Operating System (ROS) in a later module, but it is a set of open source libraries that can help with programming of robots. 

##### Militarization

- Teachers can teach that there has been consideration of using autonomous systems for militarization. This could be for making military based decisions or using these systems to take action on made military decisions. 

See also: Students can watch this [video](https://www.youtube.com/watch?v=9CO6M2HsoIA) to learn more about Slaughterbots 

#### International Traffic in Arms Regulations (ITAR)

- explain International Traffic in Arms Regulations (ITAR) and what it covers: 

See also: [website](https://digitalguardian.com/blog/what-itar-compliance)

#### Example: Predator drones utilized by the United States

- Teachers about the predator drones as an example of drones/robotic systems that are currently/previously in use by the US government related to milatary operations.

#### Should we handle autonomous weapons like chemical weapons

See also: In the US, there are two types of chemical warfare agents: stockpiled and non stockpiled. 

See also: There has been much debate if autonomous weapons should be treated like chemical weapons? Should they also be prohibited from use and fully destroyed? 

<!-- https://www.cdc.gov/nceh/demil/history.htm --> 

##### Medical, Healthcare, and Caregiver Robots

- Explain that AI/autonomous systems and their impact on medicine and healthcare.

- Describe where these systems are implemented (ex: caretaker robots, IDs, etc). 

- Explain that there are many benefits, but there are important ethical implications such as privacy/security, trust between robots and humans, and their interactions. 

#### The Emergency Exit Robot Study, Georgia Tech Howard

- Explain about experiment conducted by Georgia Institute of Technology that highlighted the potential risks of putting too much trust into robots during emergency situations that utilizes robots in a care setting and show the risks of putting to much trust into robots.

See: [Study](https://www.cc.gatech.edu/~alanwags/pubs/Robinette-HRI-2016.pdf)

##### Availability/Accessibility/Uses

- Explain robots are available to the public vs private sectors, accessibility of robots to people who may have accessibility issues, and the large amount of uses of UAV and autonomous systems. 

- Explain the effect of robot costs on consumers 

- Explain that robots can help with humanitarian and emergency effots. 

#### UN Guidelines for Emergency Uses of Drones

- Explain that drones and UAVs have been utilized by the UN. 

See: Read this [article](https://news.un.org/en/story/2017/09/564452-feature-does-drone-technology-hold-promise-un) for more information and [this](https://news.un.org/en/story/2013/12/456942-un-launches-unmanned-surveillance-aircraft-better-protect-civilians-vast-dr)

<!-- https://reliefweb.int/sites/reliefweb.int/files/resources/Drones%20in%20Humanitarian%20Action.pdf --> 

##### Future impact of AI on human jobs and responsibilities

- Explain that with the development of AI and technology, there has been a growing reliance on them as tools in our daily lives. They have a large impact on all of us: 

- Interesting [video](https://youtu.be/7Pq-S557XQU?) that can be watched: 

-  Explain ethical implications related to what AI can impact: 

See also: Automation, Job Loss, Labor Trends

See also: Impact to Democracy and Civil Rights

See also: Human-Human or Human-Agent interaction

##### Possible Assignments or Discussion Topics: 

Better: Exercise: Teachers can assign a research based group project to students (presentations/debates/discussions) on many possible topics such as: 

See also: Should code for large scale systems be open or closed source?

See also: Should autonomous cars be allowed on the road? Should robots be allowed to take care of humans?

See also: Should autonomous drones/systems be used in military operations? Should they be treated similarly to chemical weapons? 

Better: Exercise: Teachers could also assign a short report or essay to students on a component from the lesson that they are interested in (scientific writing). 

### Ending The Lesson

Recommended: 5 minutes

- Teachers can summarize ethics and the large positive and negative benefits of AI

- Teachers remind that there will be a safety module for the course coming up in one of the future classes:   

**Glossary of Terms**
Ethics: 
AI: 
DL:
ML: 
Open source code: when the source code can be accessible by the public. 
Closed source code: when the source code cannot be accessed by others, or it remains classified, only seen by those who are authorized to. 


**Useful Resources and References**

More information about the MCAS system for the Boeing 737 MAX: 
1. https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/ 

2. https://www.theverge.com/2019/5/2/18518176/boeing-737-max-crash-problems-human-error-mcas-faa

3. https://www.bbc.com/news/business-50177788

4. [Paper on Predictive Inequity in Object Detection](https://arxiv.org/pdf/1902.11097.pdf)

Moral machine links: 
5. https://www.moralmachine.net
6. https://doi.org/10.1038/s41586-018-0637-6 
7. https://ici.radio-canada.ca/info/2019/voitures-autonomes-dilemme-tramway/index-en.html

